## 第3章 小功能大用处

### 3.1 慢查询分析

> Redis客户端执行一条命令分为以下4个部分：
>
> ![](https://ws1.sinaimg.cn/large/8747d788gy1fuv6ycesxyj215o0oi122.jpg)
>
> **慢查询统计的是第3个步骤的时间**。

#### 3.1.1 慢查询的两个配置参数

> **Redis的慢查询存在内存中，使用List存储，List有长度，超过长度的日志会被会删掉，类似队列。**

可通过配置以下两个参数:

1. `slowlog-log-slower-than`：超过xx微秒的命令会被记录
2. `slowlog-max-len`：存储日志的List长度

配置方法有：

1. 修改配置文件

2. 使用config set命令

   ```shell
   config set slowlog-log-slower-than 20000 # =0会记录所有命令
   config set slowlog-max-len 1000		 	 # <0会不记录任何命令
   config rewrite # 该命令可将配置持久化到本地配置文件
   ```

管理慢查询的命令：

1. 获取慢查询日志

   `slowlog get [n]`：n指定条数

   e.g.

   ```shell
   slowlog get
   1)  1) (integer) 666		#id
       2) (integer) 1456786500 #发生时间戳
       3) (integer) 11615		#耗时
       4) 1) "BGREWRITEAOF"	#执行命令和参数
   2)  1) (integer) 665
       2) (integer) 1456718400
       3) (integer) 12006
       4)  1) "SETEX"
           2) "video_info_200"
           3) "300"
           4) "2"
   ...
   ```

2. 获取慢查询List长度

   `slowlog len`

3. 慢查询日志重置

   `slowlog reset`：实际是对列表做清理操作

#### 3.1.2 最佳实践

1.  slowlog-max-len配置建议：Redis记录并不会占用大量内存，线上可以调大一点，1000以上，防止慢查询过多被剔除过多命令。
2.  slowlog-log-slower-than配置建议：可以根据并发量配置该选项，注：默认10毫秒即为慢查询，OPS为100000。如果查询在1毫秒以上，那么Redis的OPS最多1000...
3.  客户端超时，一种可能是其他慢查询导致命令队列阻塞
4.  因为慢查询日志是一个在内存中的队列， 那么如果慢查询过多，那么会丢失部分日志。最好能够将其持久化起来（例如MySQL）

### 3.2 Redis Shell

#### 3.2.1 redis-cli 详解

| 参数              | 解释                                                         |
| ----------------- | ------------------------------------------------------------ |
| -r                | 将命令执行多次                                               |
| -i                | 命令每个几秒执行一次，配合-r使用                             |
| -x                | 选项代表从标准输入（stdin）读取数据作为redis-cli的最后一个参数 |
| -c                | Redis Cluster相关                                            |
| -a                | 设置了密码时可使用                                           |
| --scan和--pattern | 扫描指定模式的键                                             |
| --slave           | 将当前客户端模拟成当前Redis节点的从节点                      |
| --rdb             | 请求Redis实例生成并发送RDB持久化文件，保存在本地             |
| --pipe            | 将命令封装成Redis通信协议定义的数据格式，批量发送给Redis执行 |
| --bigkeys         | 选项使用scan命令对Redis的键进行采样，从中找到内存占用比较大的键值，这些键可能是系统的瓶颈 |
| --eval            | 执行指定Lua脚本                                              |
| --latency         | 有三个选项，分别是--latency、--latency-history、--latency-dist。它们都可以检测网络延迟，对于Redis的开发和运维非常有帮助。 |
| --stat            | 可以实时获取Redis的重要统计信息，虽然info命令中的统计信息更全，但是能实时看到一些增量的数据（例如requests）对于Redis的运维还是有一定帮助的 |
| --raw和--no-raw   | --no-raw选项是要求命令的返回结果必须是原始的格式，--raw恰恰相反，返回格式化后的结果 |

#### 3.2.2. redis-server详解

redis-server --test-memory xxxx

可以用来检测当前操作系统能否稳定地分配指定容量的内存给Redis，通过这种检测可以有效避免因为内存问题造成Redis崩溃。

通常无需每次开启Redis实例时都执行--test-memory选项，该功能更偏向于调试和测试，例如，想快速占满机器内存做一些极端条件的测试，这个功能是一个不错的选择。

#### 3.2.3 redis-benchmark详解

> redis-benchmark可以为Redis做基准性能测试，它提供了很多选项帮助开发和运维人员测试Redis的相关性能

| 参数          | 解释                                                         |
| ------------- | ------------------------------------------------------------ |
| -c            | -c（clients）选项代表客户端的并发数量（默认是50）            |
| -n  <request> | -n（num）选项代表客户端请求总量（默认是100000）              |
| -q            | -q选项仅仅显示redis-benchmark的requests per second信息       |
| -r            | 想向Redis插入更多的键，可以执行使用-r（random）选项，可以向Redis插入更多随机的键 |
| -P            | 代表每个请求pipeline的数据量（默认为1）                      |
| -k <boolean>  | 代表客户端是否使用keepalive，1为使用，0为不使用，默认值为1。 |
| -t            | 可以对**指定命令**进行基准测试。                             |
| --csv         | 会将结果按照csv格式输出，便于后续处理，如导出到Excel等       |



### 3.3 Pipeline

#### 3.3.1 Pipeline概念

Redis客户端执行一条命令分为如下四个过程：

1. 发送命令
2. 命令排队
3. 命令执行
4. 返回结果

其中 1和4 称为Round Trip Time（RTT，往返时间）

**问题：**虽然Redis提供了批量操作命令（例如mget、mset等），有效地节约RTT。**但大部分命令是不支持批量操作的**，例如要执行n次**hgetall**命令，并没有mhgetall命令存在，需要消耗n次RTT

**解决：**Pipeline（流水线）机制能改善上面这类问题，它能**将一组Redis命令进行组装，通过一次RTT传输给Redis，再将这组Redis命令的执行结果按顺序返回给客户端**

![](https://ws1.sinaimg.cn/large/8747d788gy1fuvbe0q9crj22fe0x5wwa.jpg)

#### 3.3.2 性能测试

在不同网络下测试，得出以下结论：

1. Pipeline执行速度一般比逐条执行要快
2. 客户端和服务端的网络延时越大， Pepeline效果越明显

![](https://ws1.sinaimg.cn/large/8747d788gy1fuvbjbxc92j21h3089diq.jpg)

#### 3.3.3 原生批量命令与Pipeline对比

1. 原生批量命令是原子的，Pipeline是非原子的。
2. 原生批量命令是一个命令对应多个key，Pipeline支持多个命令。
3. 原生批量命令是Redis服务端支持实现的，而Pipeline需要服务端和客户端的共同实现

|          | 原生批量命令        | Pipeline                     |
| -------- | ------------------- | ---------------------------- |
| 原子性   | 是                  | 否                           |
| 命令相关 | 一个命令对应多个key | 支持多个命令                 |
| 实现     | Redis服务端支持实现 | 需要服务端和客户端的共同实现 |



#### 3.3.4 最佳实践

**不要一次传输太多**，因为会增加客户端的等待时间，而且会造成一定的网络阻塞。

Pepeline只能操作一个Redis实例，但是在分布式Redis中，也可以作为批量操作的重要优化手段

### 3.4 事务与Lua

#### 3.4.1 事务

Redis提供了简单的事务功能，将一组命令放在multi和exec两条命令之间。

> 应用例子：社交应用，用户A关注了用户B，那么需要在A的关注中加入B，并在B的粉丝中添加A，要么全部执行，要么全部不执行。

如果要停止事务的执行，使用discard代替exec。

事务中出现错误的情况：

1. 命令错误，可能将set写成了sett，那么整个事务无法执行

2. 运行时错误，例如用户B在添加粉丝列表时，误把sadd命令写成了zadd命令，这种就是运行时命令，因为语法是正确的

   ```shell
   127.0.0.1:6379> multi
   OK
   127.0.0.1:6379> sadd user:a:follow user:b
   QUEUED #代表命令没有真正执行，而是暂时保存在Redis
   127.0.0.1:6379> zadd user:b:fans 1 user:a # key已经存在
   QUEUED
   127.0.0.1:6379> exec
   1) (integer) 1
   2) (error) WRONGTYPE Operation against a key holding the wrong kind of value
   127.0.0.1:6379> sismember user:a:follow user:b
   (integer) 1
   ```

   Redis不支持回滚，可以看出第一条命令已经执行了

有些场景需要在事务之前，确保事务中的key没有被其他客户端修改过，才执行事务，否则不执行（类似乐观锁）。Redis提供了watch命令来解决这类问题，如下图：

![](https://ws1.sinaimg.cn/large/8747d788gy1fuvcuvgmy6j21hy0etadp.jpg)

#### 3.4.2 Lua用法简述

#### 3.4.3 Redis与Lua

#### 3.4.4 案例

#### 3.4.5 Redis如何管理Lua脚本

### 3.5 Bitmaps

#### 3.5.1 数据结构模型

Bitmaps本身不是一种数据结构，实际上她就是字符串，但可以对字符串的位进行操作

![](https://ws1.sinaimg.cn/large/8747d788gy1fuyh1kes34j21hc07jgpg.jpg)

#### 3.5.2 命令

下面的例子以用户访问网站记录为例，访问过的为1，id为偏移量，从0开始

**感觉位图还是比较适合做签到功能，统计UV使用HyperLogLog比较省空间**

##### 1. 设置值

**setbit key offset value**

e.g. setbit unique:users:2018-09-05 10241 // id为1024的用户在2018-09-05这天访问了网站

##### 2. 获取值

**getbit key offset**

##### 3. 获取Bitmaps指定范围值为1的个数

`bitcount key [start][end]`

##### 4. Bitmaps间的运算

**bitop op destkey key [key ...]**

该操作中的op可以为and(交集)、or(并集)、not(非)、xor(异或)，并将其结果放到destkey中

e.g. 统计某2天都访问过（任意一天）网站的用户数量

##### 5. 计算Bitmaps中第一个值为targetBit的偏移量

`bitpos key targetBit [start][end]` ：start和end表示字节，不是位

#### 3.5.3 BitMaps分析

用户数量的多少决定是用那种数据结构存储统计信息：

1. 假设网站有1亿用户，每天独立访问的用户有5千万，如果每天用集合类型和Bitmaps分别存储活跃用户可以得到如下表

   ![](https://ws1.sinaimg.cn/large/8747d788gy1fuyja9901mj21ik07jdjo.jpg)

   很明显，这种情况下使用Bitmaps能节省很多的内存空间，尤其是随着时间推移节省的内存还是非常可观的：

   ![](https://ws1.sinaimg.cn/large/8747d788gy1fuyjan8ynzj21j507ltad.jpg)

2. 但Bitmaps并不是万金油，假如该网站每天的独立访问用户很少，例如只有10万（大量的僵尸用户），那么两者的对比如表所示，很显然，这时候使用Bitmaps就不太合适了，因为基本上大部分位都是0。

   ![](https://ws1.sinaimg.cn/large/8747d788gy1fuyjb5uaprj21id08dae4.jpg)

### 3.6 HyperLogLog

> **HyperLogLog**是一个基数估计算法，**只需要极少空间就可以计算超大基数**
>
> 简单来说，基数（cardinality，也译作势），是指一个集合（这里的集合允许存在重复元素）中不同元素的个数。例如看下面的集合：
> {1,2,3,4,5,2,3,9,7}
> 这个集合有9个元素，但是2和3各出现了两次，因此不重复的元素为1,2,3,4,5,9,7，所以这个集合的基数是7。
>
> PS：**pf**是HyperLogLog 这个数据结构的发明人 Philippe Flajolet 的首字母缩写

#### 1. 添加

**pfadd key element [element ...]**

#### 2. 计算独立用户数

**pfcount key [key...]**

#### 3. 合并

**pfmerge destkey sourcekey [sourcekey ...]**

#### 4. 总结

实际应用：统计网页的UV（**Unique visitor**）

选型时注意以下2点：

1. 只为了计算独立总数，不需要获取单条数据
2. 可以容忍一定误差率（官方的数字是0.81%），毕竟非常节省内存，它需要占据一定 12k 的存储空间，所以它不适合统计单个用户相关的数据

### 3.7 发布订阅

> Redis提供了的发布订阅机制，发布者跟订阅者不通过直接通信，而通过频道（channel）转发：
>
> ![](https://ws1.sinaimg.cn/large/8747d788gy1fuyonpoolbj21o00q6ds9.jpg)

#### 3.7.1 命令

##### 1. 发布消息

**publish channel message**

##### 2. 订阅消息

**subscribe channel [channel ... ]**

redis-cli：使用该命令后会一直监听消息，不处理其他命令，包括unsubscribe；而且要退出的话只是推出redis-cli，返回shell，而不是取消订阅

参考：[Redis的Pub/Sub模式](https://my.oschina.net/itblog/blog/601284)

##### 3. 取消订阅

**unsubscribe [channel [channel ...] ]**

##### 4. 按照模式订阅和取消订阅

**psubscribe pattern [pattern ... ]** 

**punsubscribe [pattern [pattern ...] ]**

##### 5. 查询订阅

1. 查看活跃的频道（至少有一个订阅者）
   **pubsub channels [pattern]**

2. 查看频道订阅数
   **pubsub numsub [channel ...]**

3. 查看模式订阅数

   这个命令返回的不是订阅模式的客户端的数量， 而是客户端订阅的所有模式的数量总和。

   **pubsub numpat**

参考：http://redisdoc.com/pub_sub/pubsub.html

#### 3.7.2应用场景

个人想到的可能是弹幕系统。

因为不支持持久化，没有很好的场景。

### 3.8 GEO

> Redis 3.2提供了GEO（地理信息定位）功能。

#### 1. 增加地理位置信息

**geoadd key longitude latitude member [longitude latitude member....]**

longitude：经度

latitude：维度

member：成员

注意返回的结果：

1. 如果新添加成功，返回1
2. 如果已经存在了，则是修改成功，返回0（如果要更新位置信息，也使用geoadd，虽然返回结果为0。）

结论：返回值是新增的数量。

#### 2. 获取地理位置信息

**geopos key menber [member...]**

```shell
127.0.0.1:6379> geopos cities:locations beijing
1) 1) "116.28000229597091675"
   2) "39.51099897006833572"
```

#### 3. 获取两个地理之位置的距离

**geodist key member1 member2 [unit]**

- m（meters）代表米。
- km（kilometers）代表公里。
- mi（miles）代表英里。
- ft（feet）代表尺。

#### 4. 获取指定位置范围内的地理信息集合

`georadius key longitude latitude radiusm|km|ft|mi [withcoord][withdist] [withhash][COUNT count] [asc|desc][store key] [storedist key]`

``georadiusbymember key member radiusm|km|ft|mi [withcoord][withdist][withhash][COUNT count] [asc|desc][store key] [storedist key]`

georadius和georadiusbymember两个命令的作用是一样的，都是以一个地理位置为中心算出指定半径内的其他地理信息位置，不同的是georadius命令的中心位置给出了具体的经纬度，georadiusbymember只需给出成员即可。其中radiusm|km|ft|mi是必需参数，指定了半径（带单位），这两个命令有很多可选参数，如下所示：

- withcoord：返回结果中包含经纬度。
- withdist：返回结果中包含离中心节点位置的距离。
- withhash：返回结果中包含geohash，有关geohash后面介绍。
- COUNT count：指定返回结果的数量。
- asc|desc：返回结果按照离中心节点的距离做升序或者降序。
- store key：将返回结果的地理位置信息保存到指定键。
- storedist key：将返回结果离中心节点的距离保存到指定键。

例子：距离北京150公里以内的城市

```shell
127.0.0.1:6379> georadiusbymember cities:locations beijing 150 km
1) "beijing"
2) "tianjin"
3) "tangshan"
4) "baoding"
```

#### 5. 获取geohash

**geohash key member [member...]**

Redis使用geohash将二维经纬度转换为一维字符串，下面操作会返回beijing的geohash值。

geohash的特点：

* GEO的数据类型为zset，Redis将所有地理位置信息的geohash存放在zset中
* 字符串越长，表示的位置更精确，表3-8给出了字符串长度对应的精度，例如geohash长度为9时，精度在2米左右
* 两个字符串越相似，它们之间的距离越近，Redis利用字符串前缀匹配算法实现相关的命令。
* geohash编码和经纬度是可以相互转换的。

![](https://ws1.sinaimg.cn/large/8747d788gy1fuytrkm8p4j20u00okaea.jpg)

#### 6. 删除地理位置信息

因为底层实现是zset，所以使用的是zrem。

**zem key member**



















